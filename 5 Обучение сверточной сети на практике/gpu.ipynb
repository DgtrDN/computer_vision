{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3603840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступные устройства: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\python_projects\\Netology\\Компьютерное зрение\\.venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 24.0 MiB for an array with shape (32, 256, 256, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Обучение модели на GPU\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 81\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Сохранение модели\u001b[39;00m\n\u001b[0;32m     85\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs_resnet_gpu.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Documents\\python_projects\\Netology\\Компьютерное зрение\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Documents\\python_projects\\Netology\\Компьютерное зрение\\.venv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:648\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_batches_of_transformed_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_array):\n\u001b[1;32m--> 648\u001b[0m     batch_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[0;32m    652\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 24.0 MiB for an array with shape (32, 256, 256, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import log_loss\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Проверяем доступность GPU\n",
    "print(\"Доступные устройства:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Включаем смешанную точность для ускорения вычислений\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Пути к данным\n",
    "train_dir = \"data/train_sample\"\n",
    "val_dir = \"data/test_sample\"\n",
    "\n",
    "# Получаем список всех изображений\n",
    "train_images = [os.path.join(train_dir, img) for img in os.listdir(train_dir) if img.endswith(('.jpg', '.png'))]\n",
    "val_images = [os.path.join(val_dir, img) for img in os.listdir(val_dir) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Проверяем наличие изображений\n",
    "assert len(train_images) > 0, \"Ошибка: нет изображений в train_sample\"\n",
    "assert len(val_images) > 0, \"Ошибка: нет изображений в test_sample\"\n",
    "\n",
    "# Функция загрузки изображений и меток\n",
    "def load_images(image_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Предупреждение: изображение {img_path} не загружено\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        img = img / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "        label = 1 if \"dog\" in img_path.lower() else 0\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Загружаем тренировочные и валидационные данные\n",
    "X_train, y_train = load_images(train_images)\n",
    "X_val, y_val = load_images(val_images)\n",
    "\n",
    "# Разделяем данные на обучение и тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Аугментация данных\n",
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                             shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "# Используем предобученную ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "base_model.trainable = True  \n",
    "\n",
    "# Замораживаем первые 2 слоя\n",
    "for layer in base_model.layers[:2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Создаём модель\n",
    "model = Sequential([base_model, Flatten(), Dense(512, activation='swish'),\n",
    "                    BatchNormalization(), Dropout(0.5), Dense(256, activation='swish'),\n",
    "                    BatchNormalization(), Dropout(0.3), Dense(1, activation='sigmoid')])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=AdamW(learning_rate=0.00003),\n",
    "              loss=tf.keras.losses.LogCosh(), metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели на GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                        epochs=75, validation_data=(X_val, y_val))\n",
    "\n",
    "# Сохранение модели\n",
    "model.save('cats_vs_dogs_resnet_gpu.h5')\n",
    "\n",
    "# Проверка Log Loss\n",
    "y_pred = model.predict(X_test)\n",
    "logloss = log_loss(y_test, y_pred)\n",
    "print(f\"Log Loss модели: {logloss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
